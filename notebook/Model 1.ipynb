{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the size of the largest image in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3408, 3320)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir('../test/') if isfile(join('../test/', f))]\n",
    "mh, mw = 0, 0\n",
    "for f in onlyfiles:\n",
    "    w, h, pixels, _ = png.Reader(filename='../test/'+f).read_flat()\n",
    "    mh = max(mh, h)\n",
    "    mw = max(mw, w)\n",
    "(mh, mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most of the images are of a different size, I would like to try a binning approach where I cluster together images of the same height and width. For each clusters, have their own dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV with image height and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59999 of 60000       60000              \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f</td>\n",
       "      <td>416</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f_flipped</td>\n",
       "      <td>416</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f_flipped_inverted</td>\n",
       "      <td>416</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000434271f63a053c4128a0ba6352c7f_inverted</td>\n",
       "      <td>416</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00053190460d56c53cc3e57321387478</td>\n",
       "      <td>416</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>fff0f82159f9083f3dd1f8967fc54f6a_inverted</td>\n",
       "      <td>416</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>fff2025e3c1d6970a8a6ee0404ac6940</td>\n",
       "      <td>416</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>fff2025e3c1d6970a8a6ee0404ac6940_flipped</td>\n",
       "      <td>416</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>fff2025e3c1d6970a8a6ee0404ac6940_flipped_inverted</td>\n",
       "      <td>416</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>fff2025e3c1d6970a8a6ee0404ac6940_inverted</td>\n",
       "      <td>416</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image_id  height  width\n",
       "0                       000434271f63a053c4128a0ba6352c7f     416    343\n",
       "1               000434271f63a053c4128a0ba6352c7f_flipped     416    343\n",
       "2      000434271f63a053c4128a0ba6352c7f_flipped_inverted     416    343\n",
       "3              000434271f63a053c4128a0ba6352c7f_inverted     416    343\n",
       "4                       00053190460d56c53cc3e57321387478     416    342\n",
       "...                                                  ...     ...    ...\n",
       "59995          fff0f82159f9083f3dd1f8967fc54f6a_inverted     416    341\n",
       "59996                   fff2025e3c1d6970a8a6ee0404ac6940     416    386\n",
       "59997           fff2025e3c1d6970a8a6ee0404ac6940_flipped     416    386\n",
       "59998  fff2025e3c1d6970a8a6ee0404ac6940_flipped_inverted     416    386\n",
       "59999          fff2025e3c1d6970a8a6ee0404ac6940_inverted     416    386\n",
       "\n",
       "[60000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import png\n",
    "csv = pd.read_csv('./augmented_train.csv')\n",
    "images = csv['image_id'].values\n",
    "images = np.unique(images)\n",
    "img, height, width = [], [], []\n",
    "for e,i in enumerate(images):\n",
    "    w, h, pixels, _ = png.Reader(filename=f'../train2/train/{i}.png').read_flat()\n",
    "    height.append(h)\n",
    "    width.append(w)\n",
    "    img.append(i)\n",
    "    print(e, \"of\", len(images), end='       \\r')\n",
    "pd.DataFrame({'image_id':img, 'height':height, 'width':width})#.to_csv('resized_height_width.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'image_id':img, 'height':height, 'width':width}).to_csv('resized_height_width.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3408, 3320])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(list(size_bins.keys()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the approach of binning into size clusters is not going to work since there are a lot of clusters with only one data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting the images into bins based on size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_bins(file='./height_width.csv'):\n",
    "    height_width_csv = pd.read_csv(file)\n",
    "    size_bins = {}\n",
    "    for r in height_width_csv.values:\n",
    "        i, h, w = r\n",
    "        if (h,w) not in size_bins.keys():\n",
    "            size_bins[(h,w)] = [i]\n",
    "        else:\n",
    "            size_bins[(h,w)].append(i)\n",
    "    \n",
    "    for k in size_bins:\n",
    "        size_bins[k] = np.unique(size_bins[k])\n",
    "    \n",
    "    return size_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1(\n",
      "  (loss): MSELoss()\n",
      "  (LeakyReLU): LeakyReLU(negative_slope=0.001)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (input): Conv2d(1, 32, kernel_size=(11, 11), stride=(5, 5))\n",
      "  (batch_input_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_1): Conv2d(32, 64, kernel_size=(11, 11), stride=(5, 5))\n",
      "  (batch_norm_conv_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_2): Conv2d(64, 128, kernel_size=(11, 11), stride=(7, 7))\n",
      "  (batch_norm_conv_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output): Conv2d(128, 71, kernel_size=(11, 11), stride=(9, 9))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import png\n",
    "from skimage import exposure\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def read_pixels(filename):\n",
    "    w, h, pixels, _ = png.Reader(filename='../train/'+filename+'.png').read_flat()\n",
    "    image = np.array(pixels).reshape(h,w)\n",
    "    return image\n",
    "\n",
    "\n",
    "def seed_everything(SEED=42):\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(64)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path, csv):\n",
    "        self.X = path\n",
    "        self.csv = csv\n",
    "        self.max_h, self.max_w = 3408, 3320\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "\n",
    "    def __pad__(self, array):\n",
    "        h,w = array.shape\n",
    "        pt = (self.max_h - h) // 2 # padding top\n",
    "        pb = self.max_h - pt - h # padding bottom\n",
    "        pl = (self.max_w - w) // 2 # padding left\n",
    "        pr = self.max_w - pl - w # padding right\n",
    "        return np.pad(array, pad_width=((pt, pb), (pl, pr)), constant_values=((0,0),(0,0))), pt, pl\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        filename = self.X[i]\n",
    "        \n",
    "        w, h, pixels, _ = png.Reader(filename=f'../train/{filename}.png').read_flat()\n",
    "        image = np.array(pixels).reshape(h,w)\n",
    "#         image = exposure.equalize_adapthist(image)\n",
    "        image, pt, pl = self.__pad__(image)\n",
    "        assert(image.shape == (self.max_h, self.max_w))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = torch.tensor(image/255.0, dtype=torch.float16)\n",
    "        \n",
    "        csv = self.csv[self.csv['image_id']==filename]\n",
    "        class_ids = csv['class_id'].values\n",
    "        \n",
    "        bboxes = csv.values[:, 4:]\n",
    "        if np.isnan(np.sum(bboxes)):\n",
    "            bboxes[:, [0, 1]] = 0.0\n",
    "            bboxes[:, [2, 3]] = 1.0\n",
    "        else:\n",
    "            bboxes = np.vectorize(lambda x: int(x))(bboxes)\n",
    "            bboxes[:, 0::2] = (bboxes[:, 0::2] + pl) / w  # normalize the x coordinates\n",
    "            bboxes[:, 1::2] = (bboxes[:, 1::2] + pt) / h  # normalize the y coordinates\n",
    "        \n",
    "        output_bboxes = np.zeros(14*4)\n",
    "        if (class_ids == 14).any(): # if there is no abnormality\n",
    "            lbl = np.zeros(15)\n",
    "        else:\n",
    "            l = np.zeros(15)\n",
    "            l[0] = 1. # there is an object of interest\n",
    "            l[class_ids] = 1. # set the expected probabilities to 1.0\n",
    "            lbl = l\n",
    "            for i,c in enumerate(class_ids):\n",
    "                output_bboxes[c*4:(c+1)*4] = bboxes[i]\n",
    "        \n",
    "        probs_bboxes = np.hstack((lbl, output_bboxes)).astype(np.float16)\n",
    "#         probs = torch.tensor(lbl, dtype=torch.long)\n",
    "#         bboxes = torch.tensor(bboxes, dtype=torch.float)\n",
    "        probs_bboxes = torch.tensor(probs_bboxes, dtype=torch.float16)\n",
    "        return image, probs_bboxes\n",
    "\n",
    "class model1(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully convolutional baseline model that is not YOLO\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layer_config, lr):\n",
    "        super(model1, self).__init__()\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        self.loss = nn.MSELoss(reduction='mean')\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.001)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.conv_layers = []\n",
    "        self.bn_layers = []\n",
    "        \n",
    "        for (k,v) in layer_config.items():\n",
    "            if k == 'input_conv':\n",
    "                self.input = nn.Conv2d(v['in_channel'], \n",
    "                                       v['out_channel'], \n",
    "                                       kernel_size = v['kernel_size'],\n",
    "                                       stride = v['stride'])\n",
    "                self.batch_input_norm = nn.BatchNorm2d(v['out_channel'])\n",
    "                \n",
    "            elif k == 'output':\n",
    "                self.output = nn.Conv2d(v['in_channel'], \n",
    "                                        v['out_channel'], \n",
    "                                        kernel_size = v['kernel_size'],\n",
    "                                        stride = v['stride'])\n",
    "            else:\n",
    "                self.conv_layers.append(nn.Conv2d(v['in_channel'], \n",
    "                                                  v['out_channel'], \n",
    "                                                  kernel_size = v['kernel_size'],\n",
    "                                                  stride = v['stride']))\n",
    "                self.bn_layers.append(nn.BatchNorm2d(v['out_channel']))\n",
    "                self.add_module(k, self.conv_layers[-1])\n",
    "                self.add_module(f'batch_norm_{k}', self.bn_layers[-1])\n",
    "    \n",
    "        self.optimizer = None\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        y = self.input(X)\n",
    "        y = self.LeakyReLU(y)\n",
    "        y = self.batch_input_norm(y)\n",
    "        \n",
    "        for c,b in zip(self.conv_layers, self.bn_layers):\n",
    "            y = c(y)\n",
    "            y = self.LeakyReLU(y)\n",
    "            y = b(y)\n",
    "        \n",
    "        y = self.output(y)\n",
    "        y = self.sigmoid(y)\n",
    "#         print(y.shape)\n",
    "        assert(y.shape[2:] == (1,1))\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def backward(self, y_hat, targets):\n",
    "        y_hat = y_hat.squeeze()\n",
    "        row_mask = (targets[:, 0] == 0.0)\n",
    "        y_hat[row_mask][:, 1:] = targets[row_mask][:, 1:]\n",
    "        \n",
    "        loss = self.loss(y_hat, targets)\n",
    "        loss_str = loss.item()\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.float()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.input.half()\n",
    "        for i in self.conv_layers:\n",
    "            i.half()\n",
    "        self.output.half()\n",
    "        \n",
    "        return loss_str\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        lo, hi = 0.4, 0.8\n",
    "        Y = self.forward(X)\n",
    "        Y = Y.squeeze()\n",
    "        output = []\n",
    "        for r in Y:\n",
    "            prob = r[0]\n",
    "            if prob <= lo:\n",
    "                output.append('14 1 0 0 1 1')\n",
    "            elif lo < prob <= hi:\n",
    "                output.append(f'14 {prob} 0 0 1 1')\n",
    "            elif prob > hi:\n",
    "                string = ''\n",
    "                classs_probs = r[1:15]\n",
    "                bboxes = r[15:]\n",
    "                for i,cp in enumerate(class_probs):\n",
    "                    if cp > 0.4:\n",
    "                        x1, y2, x2, y2 = bboxes[i*4 : (i+1)*4]\n",
    "                        string += f'{i} {cp} {x1} {y1} {x2} {y2} '\n",
    "                print(string)\n",
    "                output.append(string)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def save(self, state, path='./'):\n",
    "        torch.save(state, path)\n",
    "        \n",
    "        \n",
    "    def load(self, checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.load_state_dict(checkpoint['state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "\n",
    "layer_config = {\n",
    "    'input_conv': {\n",
    "        'in_channel': 1,\n",
    "        'out_channel': 32,\n",
    "        'kernel_size': 11,\n",
    "        'stride': 5\n",
    "    },\n",
    "    \n",
    "    'conv_1': {\n",
    "        'in_channel': 32,\n",
    "        'out_channel': 64,\n",
    "        'kernel_size': 11,\n",
    "        'stride': 5\n",
    "    },\n",
    "    \n",
    "    'conv_2': {\n",
    "        'in_channel': 64,\n",
    "        'out_channel': 128,\n",
    "        'kernel_size': 11,\n",
    "        'stride': 7\n",
    "    },\n",
    "    \n",
    "    'output': {\n",
    "        'in_channel': 128,\n",
    "        'out_channel': 1 + 14 + 14 * 4,\n",
    "        'kernel_size': 11,\n",
    "        'stride': 9\n",
    "    }\n",
    "}\n",
    "\n",
    "model = model1(layer_config, 1e-5)\n",
    "model.half()  # convert to half precision\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        layer.float()\n",
    "model.optimizer = optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-3)\n",
    "model.cuda()\n",
    "print(model)\n",
    "\n",
    "train_data = pd.read_csv(f'../augmented_train.csv')\n",
    "xtrain = np.unique(train_data['image_id'].values)\n",
    "\n",
    "batch_size = 16\n",
    "train_data = ImageDataset(xtrain, train_data)\n",
    "trainloader = DataLoader(train_data, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True, \n",
    "                         pin_memory=True,\n",
    "                         num_workers=min(batch_size, 12))\n",
    "iterations = 2\n",
    "train = False\n",
    "if train:\n",
    "    for epoc in range(iterations):\n",
    "        losses = []\n",
    "        start_time = time.time()\n",
    "        for i, (x, y) in enumerate(trainloader):\n",
    "            Y_hat = model(x.cuda())\n",
    "            losses.append(model.backward(Y_hat, y.cuda()))\n",
    "            print(f\"loss on batch {i}:\", np.round(losses[-1], 2), end='        \\r')\n",
    "        losses = np.round(np.mean(losses), 2)\n",
    "        elapsed = time.time() - start_time\n",
    "        eta = np.round(elapsed * (iterations - epoc - 1) / 3600, 2)\n",
    "        print(\"epoch:\", (epoc + 1), \" | losses:\", losses, \" | ETA:\", eta, \"hours\")\n",
    "        checkpoint = {\n",
    "            'epoch': epoc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': model.optimizer.state_dict()\n",
    "        }\n",
    "        model.save(checkpoint, './model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 649.1487894058228 seconds\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import chain\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.X = path\n",
    "        self.max_h, self.max_w = 3408, 3320\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "\n",
    "    def __pad__(self, array):\n",
    "        h,w = array.shape\n",
    "        pt = (self.max_h - h) // 2 # padding top\n",
    "        pb = self.max_h - pt - h # padding bottom\n",
    "        pl = (self.max_w - w) // 2 # padding left\n",
    "        pr = self.max_w - pl - w # padding right\n",
    "        return np.pad(array, pad_width=((pt, pb), (pl, pr)), constant_values=((0,0),(0,0))), pt, pl\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        filename = self.X[i]\n",
    "        \n",
    "        w, h, pixels, _ = png.Reader(filename=f'../test/{filename}.png').read_flat()\n",
    "        image = np.array(pixels).reshape(h,w)\n",
    "#         image = exposure.equalize_adapthist(image)\n",
    "        image, pt, pl = self.__pad__(image)\n",
    "        assert(image.shape == (self.max_h, self.max_w))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = torch.tensor(image/255.0, dtype=torch.float16)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    \n",
    "xtrain = [f.strip('.png') for f in listdir('../test/') if isfile(join('../test/', f))]\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(TestDataset(xtrain), \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False, \n",
    "                         num_workers=min(batch_size, 12))\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "model.load('./model_1.pt')\n",
    "predictions = []\n",
    "for i,x in enumerate(trainloader):\n",
    "    print(f'batch {(i+1)*batch_size} of {len(xtrain)}', end='            \\r')\n",
    "    predictions += model.predict(x.cuda())\n",
    "print(f'took {time.time() - start_time} seconds')\n",
    "pd.DataFrame({'image_id':xtrain, 'PredictionString':predictions}).to_csv('../predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
